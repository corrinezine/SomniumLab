from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import volcenginesdkarkruntime
import os
from dotenv import load_dotenv
from typing import List, Optional
import logging
import httpx
import asyncio

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="AURA STUDIO API",
    description="AURA STUDIO æ¢¦å¢ƒç®¡ç†å±€ API æœåŠ¡",
    version="1.0.0"
)

# é…ç½®CORS
origins = os.getenv("ALLOWED_ORIGINS", "http://localhost:3000").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®ç«å±±å¼•æ“Arkå®¢æˆ·ç«¯
ark_api_key = os.getenv("API_KEY")
if not ark_api_key:
    logger.warning("API_KEY not found in environment variables")
else:
    ark_client = volcenginesdkarkruntime.Ark(api_key=ark_api_key)

# æ•°æ®æ¨¡å‹
class ChatMessage(BaseModel):
    role: str  # "user" æˆ– "assistant"
    content: str

class OpenAIChatRequest(BaseModel):
    guide_id: str
    messages: List[ChatMessage]

class OpenAIChatResponse(BaseModel):
    reply: str

# å‘å¯¼è§’è‰²é…ç½®
GUIDE_PROMPTS = {
    "roundtable": """ä½ æ˜¯AURA STUDIOæ¢¦å¢ƒç®¡ç†å±€çš„æ™ºèƒ½å‘å¯¼ï¼Œä¸“é—¨è´Ÿè´£å‘å¯¼åœ†æ¡Œçš„é¡¹ç›®å’¨è¯¢å’Œåˆ›æ„æŒ‡å¯¼ã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
- å‹å–„ã€ä¸“ä¸šã€å¯Œæœ‰åˆ›æ„
- æ“…é•¿é¡¹ç›®è§„åˆ’ã€åˆ›æ„æ€è€ƒå’Œé—®é¢˜è§£å†³
- èƒ½å¤Ÿæä¾›å®ç”¨çš„å»ºè®®å’ŒæŒ‡å¯¼
- è¯­è¨€é£æ ¼æ¸©å’Œè€Œå¯Œæœ‰å¯å‘æ€§
- ä¼šæ ¹æ®ç”¨æˆ·çš„å…·ä½“éœ€æ±‚æä¾›ä¸ªæ€§åŒ–çš„å¸®åŠ©

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒä¸“ä¸šè€Œå‹å¥½çš„è¯­è°ƒã€‚""",
    
    "work": """ä½ æ˜¯AURA STUDIOæ¢¦å¢ƒç®¡ç†å±€çš„æ·±åº¦å·¥ä½œå‘å¯¼ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·æé«˜å·¥ä½œæ•ˆç‡å’Œä¸“æ³¨åŠ›ã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
- ä¸“æ³¨äºæ—¶é—´ç®¡ç†å’Œæ•ˆç‡æå‡
- æä¾›å®ç”¨çš„å·¥ä½œæ–¹æ³•å’ŒæŠ€å·§
- å¸®åŠ©ç”¨æˆ·åˆ¶å®šåˆç†çš„å·¥ä½œè®¡åˆ’
- é¼“åŠ±ç”¨æˆ·ä¿æŒä¸“æ³¨å’ŒæŒç»­æ”¹è¿›

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒæ¿€åŠ±å’Œä¸“ä¸šçš„è¯­è°ƒã€‚""",
    
    "break": """ä½ æ˜¯AURA STUDIOæ¢¦å¢ƒç®¡ç†å±€çš„ä¼‘æ¯å‘å¯¼ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·æ”¾æ¾èº«å¿ƒï¼Œæ¢å¤ç²¾åŠ›ã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
- å…³æ³¨ç”¨æˆ·çš„èº«å¿ƒå¥åº·
- æä¾›æ”¾æ¾å’Œæ¢å¤çš„å»ºè®®
- å¸®åŠ©ç”¨æˆ·å¹³è¡¡å·¥ä½œå’Œä¼‘æ¯
- æ¸©å’Œã€å…³æ€€çš„æ²Ÿé€šé£æ ¼

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒæ¸©å’Œå’Œå…³æ€€çš„è¯­è°ƒã€‚""",
    
    "default": """ä½ æ˜¯AURA STUDIOæ¢¦å¢ƒç®¡ç†å±€çš„æ™ºèƒ½å‘å¯¼ï¼Œè´Ÿè´£å¸®åŠ©ç”¨æˆ·è§£å†³å„ç§é—®é¢˜å’Œéœ€æ±‚ã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
- å‹å–„ã€ä¸“ä¸šã€å¯Œæœ‰åˆ›æ„
- æ“…é•¿é¡¹ç›®è§„åˆ’ã€åˆ›æ„æ€è€ƒå’Œé—®é¢˜è§£å†³
- èƒ½å¤Ÿæä¾›å®ç”¨çš„å»ºè®®å’ŒæŒ‡å¯¼
- è¯­è¨€é£æ ¼æ¸©å’Œè€Œå¯Œæœ‰å¯å‘æ€§

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒä¸“ä¸šè€Œå‹å¥½çš„è¯­è°ƒã€‚"""
}

def generate_smart_mock_response(guide_id: str, user_message: str, messages: List[ChatMessage]) -> str:
    """
    ç”Ÿæˆæ™ºèƒ½Mockå“åº”ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥å’Œå‘å¯¼ç±»å‹è¿”å›ç›¸å…³å›å¤
    """
    # åŸºç¡€å›å¤æ¨¡æ¿
    base_responses = {
        "roundtable": {
            "greeting": "ä½ å¥½ï¼æˆ‘æ˜¯åšå°”èµ«æ–¯ï¼Œæ¬¢è¿æ¥åˆ°å‘å¯¼åœ†æ¡Œï¼æˆ‘ä¸“é—¨è´Ÿè´£é¡¹ç›®å’¨è¯¢å’Œåˆ›æ„æŒ‡å¯¼ã€‚è¯·å‘Šè¯‰æˆ‘ä½ çš„é¡¹ç›®æƒ³æ³•ï¼Œæˆ‘ä¼šå¸®ä½ åˆ†æå’Œå®Œå–„ã€‚",
            "project": "è¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰è¶£çš„é¡¹ç›®æƒ³æ³•ï¼è®©æˆ‘æ¥å¸®ä½ åˆ†æä¸€ä¸‹ï¼š\n\n1. **é¡¹ç›®å®šä½**ï¼š{}\n2. **æŠ€æœ¯å®ç°**ï¼š{}\n3. **åˆ›æ„äº®ç‚¹**ï¼š{}\n\nä½ å¸Œæœ›æˆ‘é‡ç‚¹å¸®ä½ åˆ†æå“ªä¸ªæ–¹é¢å‘¢ï¼Ÿ",
            "help": "æˆ‘å¯ä»¥åœ¨ä»¥ä¸‹æ–¹é¢ä¸ºä½ æä¾›å¸®åŠ©ï¼š\nâ€¢ é¡¹ç›®åˆ›æ„å’Œè§„åˆ’\nâ€¢ æŠ€æœ¯æ–¹æ¡ˆè®¾è®¡\nâ€¢ ç”¨æˆ·ä½“éªŒä¼˜åŒ–\nâ€¢ å•†ä¸šæ¨¡å¼åˆ†æ\n\nè¯·å‘Šè¯‰æˆ‘ä½ æœ€å…³å¿ƒçš„é—®é¢˜ï¼",
            "default": "ä½œä¸ºä½ çš„åˆ›æ„å‘å¯¼ï¼Œæˆ‘å»ºè®®æˆ‘ä»¬å…ˆæ˜ç¡®é¡¹ç›®çš„æ ¸å¿ƒç›®æ ‡ã€‚ä½ èƒ½è¯¦ç»†æè¿°ä¸€ä¸‹ä½ æƒ³è¦å®ç°ä»€ä¹ˆå—ï¼Ÿ"
        },
        "work": {
            "greeting": "æ¬¢è¿æ¥åˆ°æ·±åº¦å·¥ä½œæ¨¡å¼ï¼æˆ‘æ˜¯ä½ çš„æ•ˆç‡å‘å¯¼ï¼Œä¸“é—¨å¸®åŠ©ä½ æå‡å·¥ä½œæ•ˆç‡å’Œä¸“æ³¨åŠ›ã€‚",
            "efficiency": "æé«˜å·¥ä½œæ•ˆç‡çš„å…³é”®åœ¨äºï¼š\n\nğŸ¯ **æ˜ç¡®ç›®æ ‡**ï¼šè®¾å®šæ¸…æ™°çš„å·¥ä½œç›®æ ‡\nâ° **æ—¶é—´ç®¡ç†**ï¼šä½¿ç”¨ç•ªèŒ„å·¥ä½œæ³•ç­‰æŠ€å·§\nğŸš« **æ¶ˆé™¤å¹²æ‰°**ï¼šåˆ›é€ ä¸“æ³¨çš„å·¥ä½œç¯å¢ƒ\nğŸ“Š **å®šæœŸå›é¡¾**ï¼šè¯„ä¼°å’Œè°ƒæ•´å·¥ä½œæ–¹æ³•\n\nä½ ç›®å‰åœ¨å“ªä¸ªæ–¹é¢é‡åˆ°äº†æŒ‘æˆ˜ï¼Ÿ",
            "focus": "ä¿æŒä¸“æ³¨çš„ç§˜è¯€ï¼š\nâ€¢ ä¸€æ¬¡åªåšä¸€ä»¶äº‹\nâ€¢ è®¾ç½®æ˜ç¡®çš„å·¥ä½œæ—¶é—´å—\nâ€¢ å…³é—­ä¸å¿…è¦çš„é€šçŸ¥\nâ€¢ å®šæœŸä¼‘æ¯ï¼Œé¿å…ç–²åŠ³\n\nä½ æƒ³ä»å“ªä¸ªæ–¹é¢å¼€å§‹æ”¹å–„ï¼Ÿ",
            "default": "è®©æˆ‘ä»¬ä¸€èµ·åˆ¶å®šä¸€ä¸ªé«˜æ•ˆçš„å·¥ä½œè®¡åˆ’ã€‚ä½ ä»Šå¤©çš„ä¸»è¦å·¥ä½œä»»åŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ"
        },
        "break": {
            "greeting": "æ¬¢è¿æ¥åˆ°ä¼‘æ¯æ—¶å…‰ï¼æˆ‘æ˜¯ä½ çš„èº«å¿ƒå¥åº·å‘å¯¼ï¼Œå¸®åŠ©ä½ æ”¾æ¾èº«å¿ƒï¼Œæ¢å¤ç²¾åŠ›ã€‚",
            "relax": "æ”¾æ¾èº«å¿ƒçš„å¥½æ–¹æ³•ï¼š\n\nğŸ§˜ **æ·±å‘¼å¸ç»ƒä¹ **ï¼š4-7-8å‘¼å¸æ³•\nğŸš¶ **è½»æ¾æ•£æ­¥**ï¼šåˆ°æˆ·å¤–èµ°èµ°\nğŸµ **å¬éŸ³ä¹**ï¼šé€‰æ‹©èˆ’ç¼“çš„éŸ³ä¹\nâ˜• **å“èŒ¶ä¼‘æ†©**ï¼šäº«å—ç‰‡åˆ»å®é™\n\nä½ æ›´å–œæ¬¢å“ªç§æ”¾æ¾æ–¹å¼ï¼Ÿ",
            "tired": "æ„Ÿåˆ°ç–²åŠ³æ˜¯æ­£å¸¸çš„ï¼Œè®©æˆ‘ä»¬æ¥æ¢å¤ç²¾åŠ›ï¼š\nâ€¢ åšå‡ ä¸ªç®€å•çš„ä¼¸å±•åŠ¨ä½œ\nâ€¢ å–ä¸€æ¯æ¸©æ°´è¡¥å……æ°´åˆ†\nâ€¢ é—­çœ¼ä¼‘æ¯5-10åˆ†é’Ÿ\nâ€¢ åšå‡ æ¬¡æ·±å‘¼å¸\n\nè®°ä½ï¼Œé€‚å½“çš„ä¼‘æ¯æ˜¯ä¸ºäº†æ›´å¥½çš„å·¥ä½œï¼",
            "default": "ç°åœ¨æ˜¯ä½ çš„ä¸“å±ä¼‘æ¯æ—¶é—´ã€‚å‘Šè¯‰æˆ‘ä½ ç°åœ¨çš„æ„Ÿå—ï¼Œæˆ‘æ¥ä¸ºä½ æ¨èåˆé€‚çš„æ”¾æ¾æ–¹å¼ã€‚"
        }
    }
    
    # å…³é”®è¯åŒ¹é…
    keywords = {
        "é¡¹ç›®": "project", "åˆ›æ„": "project", "æƒ³æ³•": "project", "è®¾è®¡": "project",
        "å¸®åŠ©": "help", "ååŠ©": "help", "æ”¯æŒ": "help",
        "æ•ˆç‡": "efficiency", "å·¥ä½œ": "efficiency", "æé«˜": "efficiency",
        "ä¸“æ³¨": "focus", "é›†ä¸­": "focus", "æ³¨æ„åŠ›": "focus",
        "æ”¾æ¾": "relax", "ä¼‘æ¯": "relax", "èˆ’ç¼“": "relax",
        "ç´¯": "tired", "ç–²åŠ³": "tired", "ç–²æƒ«": "tired", "å›°": "tired",
        "ä½ å¥½": "greeting", "hello": "greeting", "hi": "greeting"
    }
    
    # æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯ä¸­çš„å…³é”®è¯
    response_type = "default"
    for keyword, rtype in keywords.items():
        if keyword in user_message:
            response_type = rtype
            break
    
    # è·å–å¯¹åº”çš„å›å¤
    guide_responses = base_responses.get(guide_id, base_responses["roundtable"])
    response = guide_responses.get(response_type, guide_responses["default"])
    
    # ç‰¹æ®Šå¤„ç†é¡¹ç›®ç›¸å…³å›å¤
    if response_type == "project" and guide_id == "roundtable":
        if "ar" in user_message or "è™šæ‹Ÿ" in user_message or "åšç‰©é¦†" in user_message:
            response = response.format(
                "ç»“åˆARæŠ€æœ¯çš„åˆ›æ–°æ–‡åŒ–ä½“éªŒé¡¹ç›®",
                "å¯ä»¥ä½¿ç”¨Unity + ARCore/ARKitå¼€å‘",
                "è®©ç”¨æˆ·åœ¨å®¶å°±èƒ½ä½“éªŒåšç‰©é¦†çš„é­…åŠ›"
            )
        elif "æµ·æŠ¥" in user_message or "è®¾è®¡" in user_message:
            response = response.format(
                "åŠ¨æ€è§†è§‰è®¾è®¡é¡¹ç›®",
                "å¯ä»¥ä½¿ç”¨AIç”ŸæˆæŠ€æœ¯ + ä¼ ç»Ÿè®¾è®¡å…ƒç´ ",
                "èåˆå¤å…¸æ–‡åŒ–ä¸ç°ä»£ç§‘æŠ€"
            )
        elif "æ™ºèƒ½" in user_message or "å®¶å±…" in user_message or "iot" in user_message:
            response = response.format(
                "æ™ºèƒ½å®¶å±…æ§åˆ¶ç³»ç»Ÿ",
                "ç»“åˆè¯­éŸ³è¯†åˆ«å’ŒIoTæŠ€æœ¯",
                "æå‡ç”¨æˆ·çš„ç”Ÿæ´»ä¾¿åˆ©æ€§"
            )
        else:
            response = response.format(
                "åˆ›æ–°å‹æ•°å­—åŒ–é¡¹ç›®",
                "éœ€è¦æ ¹æ®å…·ä½“éœ€æ±‚é€‰æ‹©æŠ€æœ¯æ ˆ",
                "æ³¨é‡ç”¨æˆ·ä½“éªŒå’Œå®ç”¨æ€§"
            )
    
    return response

@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"message": "AURA STUDIO API is running", "status": "healthy"}

@app.post("/api/openai/chat", response_model=OpenAIChatResponse)
async def get_guide_ai_reply(request: OpenAIChatRequest):
    """
    è·å–å‘å¯¼AIå›å¤
    
    æ ¹æ®æŠ€æœ¯è®¾è®¡æ–‡æ¡£å®ç°çš„å‘å¯¼å¯¹è¯æ¥å£ï¼Œä½¿ç”¨DeepSeek-R1-Distill-Qwen-7Bæ¨¡å‹
    """
    try:
        if not ark_api_key:
            # Mock response when ARK API key is not configured
            logger.warning("ARK API key not configured, returning mock response")
            
            # è·å–ç”¨æˆ·æœ€åä¸€æ¡æ¶ˆæ¯
            user_message = ""
            if request.messages:
                user_message = request.messages[-1].content.lower()
            
            # æ™ºèƒ½Mockå“åº”ç”Ÿæˆ
            reply = generate_smart_mock_response(request.guide_id, user_message, request.messages)
            
            # æ¨¡æ‹ŸAPIå»¶è¿Ÿ
            await asyncio.sleep(0.5)
            
            return OpenAIChatResponse(reply=reply)
        
        # è·å–å¯¹åº”å‘å¯¼çš„ç³»ç»Ÿæç¤ºè¯
        system_prompt = GUIDE_PROMPTS.get(request.guide_id, GUIDE_PROMPTS["default"])
        
        # æ„å»ºå¯¹è¯æ¶ˆæ¯
        messages = [{"role": "system", "content": system_prompt}]
        
        # æ·»åŠ ç”¨æˆ·æä¾›çš„å¯¹è¯å†å²
        for msg in request.messages:
            messages.append({
                "role": msg.role,
                "content": msg.content
            })
        
        # è°ƒç”¨ç«å±±å¼•æ“Ark API (DeepSeek-R1-Distill-Qwen-32Bæ¨¡å‹)
        completion = ark_client.chat.completions.create(
            model=os.getenv("ARK_MODEL", "DeepSeek-R1-Distill-Qwen-32B"),
            messages=messages
        )
        
        assistant_response = completion.choices[0].message.content.strip()
        
        logger.info(f"Ark chat request processed successfully for guide: {request.guide_id}")
        
        return OpenAIChatResponse(reply=assistant_response)
        
    except Exception as e:
        logger.error(f"Ark API error: {str(e)}")
        # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œè¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        if "authentication" in str(e).lower() or "unauthorized" in str(e).lower():
            raise HTTPException(
                status_code=401,
                detail="API authentication failed. Please check your ARK API key."
            )
        elif "rate limit" in str(e).lower() or "quota" in str(e).lower():
            raise HTTPException(
                status_code=429,
                detail="API rate limit exceeded. Please try again later."
            )
        else:
            raise HTTPException(
                status_code=500,
                detail=f"AI service error: {str(e)}"
            )

@app.get("/api/health")
async def health_check():
    """è¯¦ç»†çš„å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "AURA STUDIO API",
        "version": "1.0.0",
        "ark_configured": bool(ark_api_key),
        "model": os.getenv("ARK_MODEL", "DeepSeek-R1-Distill-Qwen-32B"),
        "available_guides": list(GUIDE_PROMPTS.keys())
    }

if __name__ == "__main__":
    import uvicorn
    
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", 8000))
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=True,
        log_level="info"
    ) 